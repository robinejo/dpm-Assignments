TRUE ~ "other/missing/error"))
data_amp_performance_criteria <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |>
group_by(subject) |>
summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))
# determine modal number of trials
data_amp_completeness <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
group_by(subject) |>
count() |>
ungroup() |>
mutate(exclude_amp_completeness = ifelse(n == 72, "include", "exclude")) |>
select(-n)
# data_amp_completeness |>
#   count(n)
# trial level data
data_selfreport_trial_level <- data_selfreport_raw |>
select(subject, trialcode, response) |>
filter(trialcode %in% c("like", "prefer", "positive")) |>
rename(item = trialcode) |>
filter(response != "Ctrl+'B'") |>
mutate(response = as.numeric(response))
# mean scored
data_selfreport_mean_score <- data_selfreport_trial_level |>
group_by(subject) |>
summarize(mean_evaluation = mean(response, na.rm = TRUE))
# combined
data_selfreport_scored <-
full_join(data_selfreport_trial_level |>
pivot_wider(names_from = "item",
values_from = "response"),
data_selfreport_mean_score,
by = "subject")
data_amp_score_congruence <- data_amp_raw |>
select(subject, evaluative_response = correct, trialcode, blockcode) |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(trialcode = case_when(trialcode == "prime_positive" ~ 1,
trialcode == "prime_negative" ~ 0,
TRUE ~ NA),
prime_congruence = ifelse(trialcode == evaluative_response, 1, 0))
# sanity check 1: if you consider all the combiantions of factor levels of trialcode, evaluative_response, and prime congruence, there should be only 4:
data_amp_score_congruence |>
count(trialcode, evaluative_response, prime_congruence)
data_amp_score_congruence |>
count(trialcode, evaluative_response, prime_congruence) |>
nrow() == 4
# calculate AMP score
data_amp_score <- data_amp_score_congruence |>
group_by(subject) |>
summarize(AMP_score = mean(prime_congruence, na.rm = TRUE)) |>
select(subject, AMP_score)
# sanity check 2: check if AMP_score is numeric
is.numeric(data_amp_score$AMP_score)
# sanity check 3: check if AMP_score is bounded [0,1]
data_amp_score |>
mutate(bounded_correctly = between(AMP_score, left = 0, right = 1)) |>
filter(bounded_correctly != TRUE) |>
nrow() == 0
# combine all dfs created in the previous chunks
data_processed_temp <- dat_age_gender |>
full_join(data_selfreport_scored, by = "subject") |>
full_join(data_amp_score, by = "subject") |>
full_join(data_amp_performance_criteria, by = "subject") |>
full_join(data_amp_completeness, by = "subject")
# flag all subjects with more than one row in the wide-format data. these should be excluded in the analysis.
# a more elaborate approach would be to track down the individual dupicate cases and determine which of the mulitiple cases should be retained.
data_processed_duplicates <- data_processed_temp |>
count(subject) |>
mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
select(-n)
# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
full_join(data_processed_duplicates, by = "subject")
# create a master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
mutate(exclude_participant = case_when(tolower(age) == "test" ~ "exclude",
tolower(gender) == "test" ~ "exclude",
is.na(mean_evaluation) ~ "exclude",
# in this case we will exclude participants with missing demographics data or outcomes measures data.
# Note that "list-wise exclusions" like this aren't always justified, as missingness often isn't at random.
# How to treat missing data is a  whole area of work in itself, which we wont cover here.
is.na(age) ~ "exclude",
is.na(gender) ~ "exclude",
exclude_amp_performance == "exclude" ~ "exclude",
exclude_duplicate_data == "exclude" ~ "exclude",
exclude_amp_completeness == "exclude" ~ "exclude",
TRUE ~ "include"))
# in case this dir doesn't exist, create it
dir.create("../data/processed/")
# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")
View(dat_age_gender)
View(dat_mean_ratings)
View(dat_mean_ratings_by_gender)
View(data_amp_completeness)
View(data_amp_performance_criteria)
View(data_amp_raw)
View(data_amp_score)
View(data_amp_score_congruence)
View(data_amp_score)
View(data_amp_score_congruence)
View(data_amp_raw)
View(dat_age_gender)
View(data_processed)
View(data_processed_after_exclusions)
View(data_processed_before_exclusions)
View(data_processed_temp)
View(data_processed_duplicates)
p1 <- ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation,
colour = gender)) +
geom_jitter(color = viridis_pal(begin = 0.45, option = "mako")(1),
alpha = 0.5) +
geom_smooth(method = "lm",
color = viridis_pal(begin = 0.45, option = "mako")(1))
p1 +
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
ggMarginal(p1, margins = "x", size = 2, type = "histogram",
col = "black", fill = "steelblue")
p1 <- ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation,
colour = gender)) +
geom_jitter(color = viridis_pal(begin = 0.45, option = "mako")(1),
alpha = 0.5) +
geom_smooth(method = "lm",
color = viridis_pal(begin = 0.45, option = "mako")(1))
p1 +
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
ggMarginal(p1, margins = "x", size = 2, type = "histogram",
col = "black", fill = "steelblue")
p1 <- ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation,
colour = gender)) +
geom_jitter(color = viridis_pal(begin = 0.45, option = "mako")(1),
alpha = 0.5) +
geom_smooth(method = "lm",
color = viridis_pal(begin = 0.45, option = "mako")(1)) + scale_color_manual(values = c("Male" = "blue", "Female" = "pink", "Other" = "green"))
p1 +
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
ggMarginal(p1, margins = "x", size = 2, type = "histogram",
col = "black", fill = "steelblue")
scale_color_manual(values = c("Male" = "blue", "Female" = "pink", "Other" = "green"))
p1 +
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
ggMarginal(p1, margins = "x", size = 2, type = "histogram",
col = "black", fill = "steelblue")
scale_color_manual(values = c("Male" = "blue", "Female" = "pink"))
p1 +
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
ggMarginal(p1, margins = "x", size = 2, type = "histogram",
col = "black", fill = "steelblue")
p1 <- ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation,
colour = gender)) +
geom_jitter(color = viridis_pal(begin = 0.45, option = "mako")(1),
alpha = 0.5) +
geom_smooth(method = "lm",
color = viridis_pal(begin = 0.45, option = "mako")(1)) + scale_color_manual(values = c("Male" = "blue", "Female" = "pink"))
p1 +
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
ggMarginal(p1, margins = "x", size = 2, type = "histogram",
col = "black", fill = "steelblue")
p1 <- ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation,
colour = gender)) +
geom_jitter(color = viridis_pal(begin = 0.45, option = "mako")(1),
alpha = 0.5) +
geom_smooth(method = "lm",
color = viridis_pal(begin = 0.45, option = "mako")(1)) +
scale_color_manual(values = c("Male" = "blue", "Female" = "pink"))
p1 +
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
ggMarginal(p1, margins = "x", size = 2, type = "histogram",
col = "black", fill = "steelblue")
p1 <- ggplott(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation,
colour = gender)) +
geom_jitter(alpha = 0.5) +
geom_smooth(method = "lm") +
scale_color_manual(values = c("Male" = "blue", "Female" = "pink", "Other" = "green"))
p1 <- ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation,
colour = gender)) +
geom_jitter(alpha = 0.5) +
xlab("AMP score") +
ylab("Mean self-reported evaluation")
p1 <- ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation,
colour = gender)) +
geom_jitter(alpha = 0.5) +
xlab("AMP score") +
ylab("Mean self-reported evaluation")
ggMarginal(p1, groupColour = TRUE, groupFill = TRUE, type = "histogram")
ggMarginal(p1, groupColour = TRUE, groupFill = TRUE, type = "histogram")
p1 +
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
p1 +
xlab("AMP score") +
ylab("Mean self-reported evaluation") +
theme_linedraw()
ggMarginal(p1, margins = "x", size = 2, type = "histogram",
col = "black", fill = "steelblue")
ggMarginal(p1, groupColour = TRUE, groupFill = TRUE, type = "histogram")
colors <- viridis_pal(begin = 0.4, end = 0.7, option = "plasma")(10)
show_col(colors)
colors <- viridis_pal(begin = 0.4, end = 0.7, option = "plasma")(10)
colors1 <- viridis_pal(begin = 0.4, end = 0.7, option = "mako")(10)
show_col(colors)
show_col(colors1)
colors <- viridis_pal(begin = 0.1, end = 0.9, option = "plasma")(12)
colors1 <- viridis_pal(begin = 0.1, end = 0.9, option = "mako")(12)
show_col(colors)
show_col(colors1)
show_col(colors)
show_col(colors1)
install.packages(ggrepel)
install.packages("ggrepel")
library(ggrepel)
p + geom_text_repel() + labs(title = "geom_text_repel()
ggMarginal(p1, groupColour = TRUE, groupFill = TRUE, type = "histogram")
ggMarginal(p1, groupColour = TRUE, groupFill = TRUE, type = "histogram")
p + geom_text_repel() + labs(title = "geom_text_repel()
p2 <- p1 + geom_text_repel() + labs(title = "geom_text_repel()
p2 <- p1 + geom_text_repel() + labs(title = "geom_text_repel()"
p2
p2 <- p1 + geom_text_repel() + labs(title = "geom_text_repel()")
p2
+ geom_text_repel() + labs(title = "geom_text_repel()")
ggMarginal(p1, groupColour = TRUE, groupFill = TRUE, type = "histogram") |>
geom_text_repel() + labs(title = "geom_text_repel()")
p2 <- p1 + geom_text_repel() + labs(title = "geom_text_repel()")
p2
ggMarginal(p1, groupColour = TRUE, groupFill = TRUE, type = "histogram")
p2 <- p1 + geom_text_repel() + labs(title = "geom_text_repel()")
p2
ggMarginal(p1, groupColour = TRUE, groupFill = TRUE, type = "histogram")
p2 <- p1 + geom_text_repel() + labs(title = "geom_text_repel()")
p2
View(data_processed_after_exclusions)
p1 <- ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation,
colour = gender)) +
geom_jitter(alpha = 0.5) +
xlab("AMP score") +
ylab("Mean self-reported evaluation")
ggMarginal(p1, groupColour = TRUE, groupFill = TRUE, type = "histogram")
p2 <- p1 + geom_text_repel() + labs(title = "geom_text_repel()")
p2
p1 <- ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation,
colour = gender)) +
geom_jitter(alpha = 0.5) +
xlab("AMP score") +
ylab("Mean self-reported evaluation")
ggMarginal(p1, groupColour = TRUE, groupFill = TRUE, type = "histogram")
p1 <- ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation,
colour = gender)) +
geom_jitter(alpha = 0.5) +
xlab("AMP score") +
ylab("Mean self-reported evaluation")
p2 <- p1 + geom_text_repel() + labs(title = "geom_text_repel()")
p2
p1 <- ggplot(data_processed_after_exclusions,
aes(x = AMP_score,
y = mean_evaluation,
colour = gender,
label = subject)) +
geom_jitter(alpha = 0.5) +
xlab("AMP score") +
ylab("Mean self-reported evaluation")
p2 <- p1 + geom_text_repel() + labs(title = "geom_text_repel()")
p2
View(data_amp_score_congruence)
View(data_amp_score)
View(data_selfreport_trial_level)
View(data_selfreport_scored)
View(data_selfreport_raw)
outliers <- identify_outliers(data_processed_after_exclusions$AMP_score)
?identify_outliers
# formatting options
# set default chunk options
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# disable scientific notation
options(scipen = 999)
# dependencies
library(tidyverse)
library(lavaan)
library(janitor)
library(knitr)
library(kableExtra)
library(Matrix)
# library(devtools)
# install_github("ianhussey/ERROR")
library(ERROR)
# library(devtools)
# install_github("ianhussey/ERROR")
devtools::install_github("ianhussey/ERROR")
# library(devtools)
# install_github("ianhussey/ERROR")
devtools::install_github("ianhussey/ERROR")
library(ERROR)
?ERROR
#D&D Syntax
library(car)
library(psych)
library(Hmisc)
library(readxl)
library(lavaan)
library(semTools)
library(corrplot)
library(GPArotation)
library(apaTables)
library(effectsize)
data_dnd<-read.csv("../Data/Lorenz, Hagitte, & Brandt. D&D Data.csv",sep = ";",na.strings = "-77")
attach(data_dnd)
data_dnd$classes_new<- recode(data_dnd$classes,"0=-77")
data_dnd <- data_dnd %>%
select(sort(names(.)))
#t-tests for each Big5 factor dnd vs non dnd
#bonferroni-Holm
data_dnd$status <- factor(data_dnd$status,
levels = 1:2,
labels = c("player", "non_player"))
attach(data_dnd)
#means
extra<- data.frame(e1, e2, e3, e4, e5, e6, e7, e8)
con <- data.frame(c1, c2, c3, c4, c5, c5, c6, c7, c8, c9)
open <- data.frame(o1, o2, o3, o4, o5, o6, o7, o8, o9, o10)
agree <- data.frame(a1, a2, a3, a4, a5, a6, a7, a8, a9)
neuro <- data.frame(n1, n2, n3, n4, n5, n6, n7, n8)
charisma <- data.frame(charisma)
data_dnd$extra_m <- rowMeans(extra)
data_dnd$con_m <- rowMeans(con)
data_dnd$open_m <- rowMeans(open)
data_dnd$agree_m <- rowMeans(agree)
data_dnd$neuro_m <- rowMeans(neuro)
data_dnd$charisma_n <- rowMeans(charisma)
View(data_dnd)
# Overview demographics
dnd_demographics_overview <- data_dnd |>
select(charisma, classes, classes_new, education, sex, status)
View(dnd_demographics_overview)
dnd_demographics_overview |> count(status)
count(status)
count(dnd_demographics_overview$status)
summarise(dnd_demographics_overview)
# Overview demographics
dnd_demographics_overview <- data_dnd |>
select(charisma, classes, classes_new, education, sex, status) |>
filter(status == player)
# Overview demographics
dnd_demographics_overview <- data_dnd |>
select(charisma, classes, classes_new, education, sex, status) |>
filter(status == non_player)
# Overview demographics
dnd_demographics_overview <- data_dnd |>
select(charisma, classes, classes_new, education, sex, status)
# Overview demographics
dnd_demographics_overview <- data_dnd |>
select(charisma, classes, classes_new, education, sex, status) |>
filter(status == "player")
#D&D Syntax
library(car)
library(psych)
library(Hmisc)
library(readxl)
library(lavaan)
library(semTools)
library(corrplot)
library(GPArotation)
library(apaTables)
library(effectsize)
data_dnd<-read.csv("../Data/Lorenz, Hagitte, & Brandt. D&D Data.csv",sep = ";",na.strings = "-77")
#D&D Syntax
library(car)
library(psych)
library(Hmisc)
library(readxl)
library(lavaan)
library(semTools)
library(corrplot)
library(GPArotation)
library(apaTables)
library(effectsize)
data_dnd<-read.csv("../Data/Lorenz, Hagitte, & Brandt. D&D Data.csv",sep = ";",na.strings = "-77")
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(janitor) # for clean_names()
library(stringr)
library(openxlsx)
# demographics
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv") |>
janitor::clean_names()
# data_demographics_raw_messy <- read_csv("../data/raw/data_demographics_raw_messy.csv", skip = 2) |>
#   janitor::clean_names()
# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv") |>
janitor::clean_names()
# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv") |>
janitor::clean_names()
dat_age_gender <- data_demographics_raw |>
select(subject, date, time, trialcode, response) |>
pivot_wider(names_from = trialcode,
values_from = response) |>
mutate(gender = tolower(gender),
gender = stringr::str_remove_all(gender, regex("\\W+")), # regex is both very useful and awful to write
gender = case_when(gender == "female" ~ gender,
gender == "male" ~ gender,
gender == "nonbinary" ~ gender,
gender == "woman" ~ "female",
gender == "man" ~ "male",
TRUE ~ "other/missing/error"),
age = case_when(str_detect(age, "^[0-9]+$") ~ age, # if the value is only numbers, keep it.
TRUE ~ "other/missing/error"))
data_amp_performance_criteria <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |>
group_by(subject) |>
summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))
data_amp_performance_criteria <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |>
group_by(subject) |>
summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(janitor) # for clean_names()
library(stringr)
library(openxlsx)
# demographics
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv") |>
janitor::clean_names()
# data_demographics_raw_messy <- read_csv("../data/raw/data_demographics_raw_messy.csv", skip = 2) |>
#   janitor::clean_names()
# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv") |>
janitor::clean_names()
# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv") |>
janitor::clean_names()
dat_age_gender <- data_demographics_raw |>
select(subject, date, time, trialcode, response) |>
pivot_wider(names_from = trialcode,
values_from = response) |>
mutate(gender = tolower(gender),
gender = stringr::str_remove_all(gender, regex("\\W+")), # regex is both very useful and awful to write
gender = case_when(gender == "female" ~ gender,
gender == "male" ~ gender,
gender == "nonbinary" ~ gender,
gender == "woman" ~ "female",
gender == "man" ~ "male",
TRUE ~ "other/missing/error"),
age = case_when(str_detect(age, "^[0-9]+$") ~ age, # if the value is only numbers, keep it.
TRUE ~ "other/missing/error"))
data_amp_performance_criteria <- data_amp_raw |>
filter(blockcode != "practice",
trialcode != "instructions") |>
mutate(latency_prob = if_else(latency < 100, TRUE, FALSE)) |>
group_by(subject) |>
summarize(proportion_fast_trials_amp = mean(latency_prob)) |>
mutate(exclude_amp_performance = ifelse(proportion_fast_trials_amp > 0.10, "exclude", "include"))
data_dnd<-read.csv("../data/Lorenz, Hagitte, & Brandt. D&D Data.csv",
sep = ";",
na.strings = "-77")
attach(data_dnd)
data_dnd$classes_new<- recode(data_dnd$classes,"0=-77")
View(data_dnd)
mutate(classes_new = ifelse(classes == 0, '77, classes))
data_dnd <- data_dnd |>
mutate(classes_new = ifelse(classes == 0, -77, classes))
attach(data_dnd)
